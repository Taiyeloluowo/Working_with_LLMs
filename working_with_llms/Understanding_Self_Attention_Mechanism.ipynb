{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Using Numpy to Create self attention"
      ],
      "metadata": {
        "id": "RJmE2LlE_F8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Think of Self-Attention Like a Classroom Discussion\n",
        "Imagine you are in a classroom discussing the sentence:\n",
        "\n",
        " **\"The cat sat on the mat.\"**\n",
        "\n",
        "You are the teacher, and you want to understand what each word in the sentence means in context by looking at all the other words."
      ],
      "metadata": {
        "id": "7pV-BULh16Ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1: Understanding the Need for Attention\n",
        "Each word in a sentence has a meaning, but its meaning depends on other words too.\n",
        "\n",
        "Example:\n",
        "\n",
        "The word \"sat\" means \"to be in a sitting position.\"\n",
        "But who is sitting? (\"cat\" is the subject).\n",
        "Where? (\"on the mat\" tells us the location)\n",
        "\n",
        "Instead of looking at words one by one, self-attention allows each word to \"ask\" other words for relevant information."
      ],
      "metadata": {
        "id": "o8moBb5a1_xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Assigning Roles – Queries, Keys, and Values\n",
        "To help each word decide what to focus on, we give each word three roles:\n",
        "\n",
        "1. Query (Q) – The Question:\n",
        "\n",
        "Each word \"asks\" about the meaning of the sentence from its perspective.\n",
        "Example: \"What is important for me to understand?\"\n",
        "\n",
        "2. Key (K) – The Information Holder:\n",
        "\n",
        "Each word \"offers\" its meaning to others.\n",
        "Example: \"This is what I mean, take it if needed.\"\n",
        "\n",
        "3. Value (V) – The Final Meaning:\n",
        "\n",
        "Each word carries useful information that will be passed to others.\n",
        "\n",
        "Think of this like students asking and answering questions in a classroom.\n",
        "\n",
        "If you are the student (Query), you ask important questions (Q).\n",
        "The other students (Keys) provide answers (K).\n",
        "You collect and process those answers (V) to understand better.\n"
      ],
      "metadata": {
        "id": "8gUv71fA2KZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Scoring the Importance of Words\n",
        "Now, each word \"talks\" to every other word and decides how important they are.\n",
        "\n",
        "How? By comparing Queries (Q) and Keys (K)!\n",
        "\n",
        "If a word’s Query (Q) matches well with another word’s Key (K), that means it’s important.\n",
        "The higher the match, the more attention it gets!"
      ],
      "metadata": {
        "id": "EuygRoqf2Yhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 4: Making the Attention Weights\n",
        "Now that we have scores, we want to convert them into a proper weight (like a probability).\n",
        "\n",
        "How? By applying softmax():\n",
        "\n",
        "It makes the most important words stand out (high scores become bigger, low scores become smaller).\n",
        "The total attention across all words sums to 1 (100%)."
      ],
      "metadata": {
        "id": "DeH6fFoH2dKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Updating the Meaning Using Values (V)\n",
        "Each word now mixes information from other words using the attention weights.\n",
        "\n",
        "Each word’s final meaning is a blend of the words it pays attention to!\n",
        "\n",
        "Example:\n",
        "\n",
        "\"sat\" borrows information from \"cat\" and \"on\" (because they got high attention scores).\n",
        "This helps \"sat\" understand that it refers to the cat sitting on something."
      ],
      "metadata": {
        "id": "slfyrNd42k1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Q = X @ W_Q\n",
        "K = X @ W_K\n",
        "V = X @ W_V\n",
        "```\n",
        "`Attention_Scores = Q @ K.T\n",
        "`\n",
        "\n",
        "`Scaled_Scores = Attention_Scores / sqrt(d_k)\n",
        "`\n",
        "\n",
        "`Attention_Weights = softmax(Scaled_Scores)\n",
        "`\n",
        "\n",
        "`Output = Attention_Weights @ V\n",
        "`\n",
        "\n",
        "```\n",
        "Self_Attention(Q, K, V) = softmax((Q @ K.T) / sqrt(d_k)) @ V\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "p2yhVn7qAD3M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSmFut6a_zaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqni3FGn1nCL"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input(Word embeddings)\n",
        "x = np.array([[1, 0, 1],  # Word 1\n",
        "    [0, 1, 1],  # Word 2\n",
        "    [1, 1, 0]   # Word 3\n",
        "])\n",
        "print(\"Input word embeddings:\", x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hrBweAL2xL5",
        "outputId": "8ed62ccb-a9b5-488d-90fc-cae8a497bbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word embeddings: [[1 0 1]\n",
            " [0 1 1]\n",
            " [1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Query(Q), Key(K), and Value(V) matrices using random numbers\n",
        "q = np.random.rand(3, 3)\n",
        "k = np.random.rand(3, 3)\n",
        "v = np.random.rand(3, 3)"
      ],
      "metadata": {
        "id": "vEbNfCA62xIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dirKe5OR6-M9",
        "outputId": "617a34d6-d751-49f6-9bdc-e6e3633839d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02982655 0.86754356 0.32277036]\n",
            " [0.67090353 0.28066548 0.02169685]\n",
            " [0.99935554 0.07557419 0.15867828]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(q[0])\n",
        "print(q[1])\n",
        "print(q[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjIPNq_C6Qqs",
        "outputId": "0e728ac3-4154-47c9-b637-53b21d1cb159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.02982655 0.86754356 0.32277036]\n",
            "[0.67090353 0.28066548 0.02169685]\n",
            "[0.99935554 0.07557419 0.15867828]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"row:\",q.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDhWG5nm6PWj",
        "outputId": "f024130d-61d7-4c2f-f91a-031b96d5946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "row: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"col:\",q.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byP5WdZj6a3y",
        "outputId": "f9b1bdd2-28eb-4136-8302-3a164db1950b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "col: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute q, k  and v\n",
        "# Using dot product # (3x3) @ (3x3) --> 3\n",
        "q_x = np.dot(x, q)\n",
        "k_x = np.dot(x, k)\n",
        "v_x = np.dot(x, v)"
      ],
      "metadata": {
        "id": "WD6rHJwQ2xDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Query:\", q_x, \"\\n\")\n",
        "print(\"Key:\", k_x, \"\\n\")\n",
        "print(\"Value:\", v_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzaJf0KJ5yp7",
        "outputId": "660b7d78-8e2a-4a21-c825-e115b21e0dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: [[1.02918209 0.94311775 0.48144864]\n",
            " [1.67025907 0.35623968 0.18037514]\n",
            " [0.70073007 1.14820905 0.34446721]] \n",
            "\n",
            "Key: [[0.88059947 0.96738799 0.82429994]\n",
            " [0.55447921 1.09563113 0.14715601]\n",
            " [0.96527645 1.57565102 0.70314209]] \n",
            "\n",
            "Value: [[1.26402321 1.5142024  1.32318979]\n",
            " [1.48882578 1.90282565 1.06119132]\n",
            " [1.32802383 1.49405674 1.10095084]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute attention scores,dot T transpose\n",
        "# Using dot product # (3x3) @ (3x3) --> 3\n",
        "attention_scores = np.dot(q_x, k_x.T)"
      ],
      "metadata": {
        "id": "7zPIHXkk9SNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yHwKvyF-P6D",
        "outputId": "36bfb698-7b54-4560-9e24-2d4eee6bc9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.21551608 1.6748173  2.81799649]\n",
            " [1.96413445 1.34297449 2.3004005 ]\n",
            " [2.01177048 1.69724425 2.72778439]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply softmax function\n",
        "def softmax(x):\n",
        "    return np.exp(x)/ np.sum(np.exp(x), axis = 1, keepdims = True)"
      ],
      "metadata": {
        "id": "oyhre1Jg5RRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets apply the softmax to get attention weights\n",
        "attention_weights = softmax(attention_scores)"
      ],
      "metadata": {
        "id": "uCbAd-Rm2xAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V7F5_4O-dDE",
        "outputId": "8f684839-09d1-4c9f-d4fc-e72163f6970a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29334243, 0.17082538, 0.53583219],\n",
              "       [0.34047976, 0.18294686, 0.47657339],\n",
              "       [0.2648028 , 0.19334172, 0.54185548]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the final output (weighted sum of Values)\n",
        "output = attention_weights @ v_x # (3x3) @ (3x3) -> (3x3)\n",
        "\n",
        "print(\"Final Output After Self-Attention:\\n\\n\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9lJGo4z2w2p",
        "outputId": "7ac5e0b6-ff93-44d8-bac4-862717182400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Output After Self-Attention:\n",
            "\n",
            " [[1.33671879 1.56979442 1.15935102]\n",
            " [1.33565113 1.57569892 1.16934482]\n",
            " [1.34216601 1.57842345 1.15211316]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Pytorch to Create self attention"
      ],
      "metadata": {
        "id": "Q5b2q6-3_P9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "zCfUruMU_Tos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"I am a machine learning engineer\"\n",
        "\n",
        "# lets define word vocab\n",
        "word_vocab = dict(enumerate(word.split()))"
      ],
      "metadata": {
        "id": "3bv8FKNQBaUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJwNyCbTEzHM",
        "outputId": "d8af5884-daf0-45ef-816e-7f8875906445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'I', 1: 'am', 2: 'a', 3: 'machine', 4: 'learning', 5: 'engineer'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_dict(input_dict):\n",
        "  return {value: key for key, value in input_dict.items()}"
      ],
      "metadata": {
        "id": "GBDTCzzNBaGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = reverse_dict(word_vocab)"
      ],
      "metadata": {
        "id": "qEf5xpoFBaJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZnrWTqQBZ_b",
        "outputId": "bdd05660-159f-4ae2-c492-47ec0c58e7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': 0, 'am': 1, 'a': 2, 'machine': 3, 'learning': 4, 'engineer': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "# define embedding dimension\n",
        "embedding_dim = 4"
      ],
      "metadata": {
        "id": "_jQB-N9tE7yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create  an embedding layer\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)"
      ],
      "metadata": {
        "id": "aMpT8SYTFSF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentence into token indices\n",
        "token_indices = [vocab[word] for word in word.split()]\n",
        "input_indices = torch.tensor(token_indices)"
      ],
      "metadata": {
        "id": "lW7MD_6XFSCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get word embeddings\n",
        "X = embedding_layer(input_indices)"
      ],
      "metadata": {
        "id": "v4qpNgSEFR41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape\n",
        "#(num_words, embedding_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYpO8bq0GfVs",
        "outputId": "a3f52b51-806a-4d79-ec4f-2a42d69fa091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCzeCzZ1Gted",
        "outputId": "3a11c93f-9a42-4c11-f1a4-bf78a61966c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1552,  1.0317,  1.5787, -1.3859],\n",
            "        [-0.0997,  0.3827, -0.5121, -0.7133],\n",
            "        [-0.8429, -0.0120, -1.1839, -1.6159],\n",
            "        [ 0.3314,  1.6603, -0.1966, -0.3770],\n",
            "        [ 1.4558,  2.6057, -0.7224, -1.8245],\n",
            "        [-0.9696, -1.8205,  0.2053, -0.0396]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets compute for Q,K and V\n",
        "\n",
        "# Define trainable weights matrices (embedding_dim, embedding_dim)\n",
        "\n",
        "W_Q = torch.randn(embedding_dim, embedding_dim)\n",
        "W_K = torch.randn(embedding_dim, embedding_dim)\n",
        "W_V = torch.randn(embedding_dim, embedding_dim)"
      ],
      "metadata": {
        "id": "7CWKS4rSGxuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Q, K, V\n",
        "Q = X @ W_Q  # (6,4) @ (4,4) -> (6,4)\n",
        "K = X @ W_K  # (6,4) @ (4,4) -> (6,4)\n",
        "V = X @ W_V  # (6,4) @ (4,4) -> (6,4)"
      ],
      "metadata": {
        "id": "akrvq09wHGOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nQuery (Q):\\n\", Q)\n",
        "print(\"\\nKey (K):\\n\", K)\n",
        "print(\"\\nValue (V):\\n\", V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTcQhAaxHK-l",
        "outputId": "a0561e31-1627-461c-953a-c7b85ca6f048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query (Q):\n",
            " tensor([[ 0.8388, -0.4577, -1.4179, -3.4429],\n",
            "        [ 0.3344,  1.4597, -0.6583, -0.8520],\n",
            "        [ 2.3609,  3.7756, -1.6642, -1.0781],\n",
            "        [-2.0661,  0.4086, -0.6198, -1.9695],\n",
            "        [-2.3459,  1.7674, -0.8779, -3.9946],\n",
            "        [ 3.2354,  0.4677, -0.1180,  1.6178]], grad_fn=<MmBackward0>)\n",
            "\n",
            "Key (K):\n",
            " tensor([[-0.0987, -4.3516, -2.8646, -5.3264],\n",
            "        [ 0.2254, -0.0270,  0.9004,  1.1313],\n",
            "        [-0.6867,  1.9948,  2.4314,  3.6758],\n",
            "        [ 1.5325, -2.9488,  0.1252, -1.2027],\n",
            "        [ 3.1263, -5.1399,  0.2864, -0.8180],\n",
            "        [-2.2940,  3.6204,  0.1796,  1.5265]], grad_fn=<MmBackward0>)\n",
            "\n",
            "Value (V):\n",
            " tensor([[ 1.2768, -3.3923, -3.0889,  0.2982],\n",
            "        [ 1.1344,  0.6626, -0.1441, -1.0227],\n",
            "        [ 1.0953,  1.1428, -0.0482, -1.3260],\n",
            "        [ 2.7697,  1.3958, -0.5323, -3.0442],\n",
            "        [ 5.5748,  0.8515, -1.4998, -3.0465],\n",
            "        [-3.0427, -1.5246,  0.2519,  2.7946]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets compute Attention Scores (dot product of Q and K^T)\n",
        "attention_scores = Q @ K.T\n",
        "\n",
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm__U4aoHR0t",
        "outputId": "9d270793-5ecf-4377-edbf-f400013c43e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 24.3090,  -4.9704, -17.5920,   6.5986,   7.3851,  -9.0916],\n",
            "        [  0.0386,  -1.5207,  -2.0501,  -2.8497,  -5.9490,   3.0988],\n",
            "        [ -6.1531,  -2.2881,  -2.0991,  -6.4270, -11.6200,   6.3085],\n",
            "        [ 10.6912,  -3.2630,  -6.5124,  -2.0802,  -7.1261,   3.1014],\n",
            "        [ 16.3321,  -5.8863, -11.6813,  -4.1122, -13.4019,   5.5247],\n",
            "        [-10.6333,   2.4407,   4.3708,   1.6188,   6.3541,  -3.2807]],\n",
            "       grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets scale the scores\n",
        "scaled_scores = attention_scores / (embedding_dim ** 0.5)\n",
        "#scaled_scores = attention_scores / torch.sqrt(torch.tensor(embedding_dim, dtype=torch.float32))\n",
        "scaled_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va1jePzFHlp-",
        "outputId": "dd1cab4a-36ad-43b9-fdca-c1d39aa28106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12.1545, -2.4852, -8.7960,  3.2993,  3.6925, -4.5458],\n",
              "        [ 0.0193, -0.7604, -1.0251, -1.4248, -2.9745,  1.5494],\n",
              "        [-3.0766, -1.1440, -1.0496, -3.2135, -5.8100,  3.1542],\n",
              "        [ 5.3456, -1.6315, -3.2562, -1.0401, -3.5630,  1.5507],\n",
              "        [ 8.1661, -2.9431, -5.8407, -2.0561, -6.7010,  2.7623],\n",
              "        [-5.3166,  1.2203,  2.1854,  0.8094,  3.1770, -1.6404]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply softmax\n",
        "attention_weights = F.softmax(scaled_scores, dim=-1)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCo1xjoBILNO",
        "outputId": "adc2bd20-7a13-416f-ed94-c2436e7877cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.9965e-01, 4.3843e-07, 7.9644e-10, 1.4258e-04, 2.1128e-04, 5.5847e-08],\n",
            "        [1.4891e-01, 6.8287e-02, 5.2405e-02, 3.5136e-02, 7.4601e-03, 6.8780e-01],\n",
            "        [1.9062e-03, 1.3166e-02, 1.4471e-02, 1.6622e-03, 1.2390e-04, 9.6867e-01],\n",
            "        [9.7521e-01, 9.0988e-04, 1.7922e-04, 1.6437e-03, 1.3186e-04, 2.1928e-02],\n",
            "        [9.9547e-01, 1.4906e-05, 8.2222e-07, 3.6190e-05, 3.4783e-07, 4.4794e-03],\n",
            "        [1.2684e-04, 8.7545e-02, 2.2980e-01, 5.8045e-02, 6.1947e-01, 5.0101e-03]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute final output\n",
        "output = attention_weights @ V\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT26qwqCITw0",
        "outputId": "591e17a1-8d2f-4d62-eb40-227693f1109a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2780, -3.3907, -3.0882,  0.2970],\n",
            "        [-1.6289, -1.3933, -0.3290,  1.6975],\n",
            "        [-2.9089, -1.4556,  0.2345,  2.6695],\n",
            "        [ 1.1850, -3.3384, -3.0080,  0.3455],\n",
            "        [ 1.2575, -3.3837, -3.0738,  0.3092],\n",
            "        [ 3.9501,  0.9211, -0.9828, -2.4441]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}